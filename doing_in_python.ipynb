{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import stupidf as sf\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_scaling_info_and_apply(stdf_file):\n",
    "    \"\"\"\n",
    "    Extract scaling information from raw STDF and apply it to create scaled columns\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Loading STDF data...\")\n",
    "    \n",
    "    # Get the regular DataFrame (this has the test results)\n",
    "    stdf_parsed = sf.parse_stdf(stdf_file)\n",
    "    df = stdf_parsed['df']\n",
    "    \n",
    "    # Get the raw STDF object (this has detailed PTR info including scaling)\n",
    "    raw_stdf = sf.get_raw_stdf(stdf_file)\n",
    "    \n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    print(f\"DataFrame columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Extract scaling information from the full test information\n",
    "    full_test_info = raw_stdf.test_data.full_test_information\n",
    "    \n",
    "    print(f\"Found {len(full_test_info)} test information records\")\n",
    "    \n",
    "    # Create dictionaries to store scaling info by test_num\n",
    "    scaling_info = {}\n",
    "    \n",
    "    # Extract scaling data from each test information record\n",
    "    for (test_num, site_num, head_num), test_info in full_test_info.items():\n",
    "        if test_num not in scaling_info:\n",
    "            scaling_info[test_num] = {\n",
    "                'units': getattr(test_info, 'units', ''),\n",
    "                'res_scal': None,\n",
    "                'llm_scal': None, \n",
    "                'hlm_scal': None,\n",
    "                'low_limit': getattr(test_info, 'low_limit', None),\n",
    "                'high_limit': getattr(test_info, 'high_limit', None)\n",
    "            }\n",
    "    \n",
    "    print(f\"Extracted scaling info for {len(scaling_info)} unique tests\")\n",
    "    \n",
    "    # Alternative: Parse the raw records directly to get PTR scaling info\n",
    "    # This is more reliable since the test_information might not have all scaling data\n",
    "    print(\"Parsing raw records for PTR scaling information...\")\n",
    "    \n",
    "    ptr_scaling_info = extract_ptr_scaling_from_raw(stdf_file)\n",
    "    \n",
    "    # Merge the two sources of information\n",
    "    for test_num in ptr_scaling_info:\n",
    "        if test_num in scaling_info:\n",
    "            scaling_info[test_num].update(ptr_scaling_info[test_num])\n",
    "        else:\n",
    "            scaling_info[test_num] = ptr_scaling_info[test_num]\n",
    "    \n",
    "    print(f\"Total scaling info for {len(scaling_info)} tests\")\n",
    "    \n",
    "    # Convert DataFrame to pandas for easier manipulation\n",
    "    df_pandas = df.to_pandas()\n",
    "    \n",
    "    # Find parametric test columns (numeric column names)\n",
    "    param_columns = [col for col in df_pandas.columns if col.isdigit()]\n",
    "    print(f\"Found {len(param_columns)} parametric test columns: {param_columns[:10]}\")\n",
    "    \n",
    "    # Apply scaling to each parametric test\n",
    "    new_columns = {}\n",
    "    \n",
    "    for test_num_str in param_columns:\n",
    "        test_num = int(test_num_str)\n",
    "        \n",
    "        if test_num in scaling_info:\n",
    "            info = scaling_info[test_num]\n",
    "            \n",
    "            # Get the raw results column\n",
    "            raw_values = df_pandas[test_num_str]\n",
    "            \n",
    "            # Apply scaling if res_scal is available\n",
    "            if info.get('res_scal') is not None:\n",
    "                res_scal = info['res_scal']\n",
    "                scaled_values = raw_values * (10 ** res_scal)\n",
    "                new_columns[f\"{test_num}_scaled\"] = scaled_values\n",
    "                new_columns[f\"{test_num}_res_scal\"] = res_scal\n",
    "                print(f\"Test {test_num}: Applied scaling 10^{res_scal}\")\n",
    "            else:\n",
    "                # No scaling, but still create scaled column (same as raw)\n",
    "                new_columns[f\"{test_num}_scaled\"] = raw_values\n",
    "                new_columns[f\"{test_num}_res_scal\"] = 0\n",
    "            \n",
    "            # Add other scaling info\n",
    "            if info.get('llm_scal') is not None:\n",
    "                new_columns[f\"{test_num}_llm_scal\"] = info['llm_scal']\n",
    "            \n",
    "            if info.get('hlm_scal') is not None:\n",
    "                new_columns[f\"{test_num}_hlm_scal\"] = info['hlm_scal']\n",
    "            \n",
    "            # Add units\n",
    "            units = info.get('units', '')\n",
    "            if units:\n",
    "                new_columns[f\"{test_num}_units\"] = units\n",
    "            \n",
    "            # Add scaled limits if available\n",
    "            if info.get('low_limit') is not None and info.get('llm_scal') is not None:\n",
    "                llm_scal = info['llm_scal']\n",
    "                scaled_low_limit = info['low_limit'] * (10 ** llm_scal)\n",
    "                new_columns[f\"{test_num}_low_limit_scaled\"] = scaled_low_limit\n",
    "                \n",
    "            if info.get('high_limit') is not None and info.get('hlm_scal') is not None:\n",
    "                hlm_scal = info['hlm_scal']\n",
    "                scaled_high_limit = info['high_limit'] * (10 ** hlm_scal)\n",
    "                new_columns[f\"{test_num}_high_limit_scaled\"] = scaled_high_limit\n",
    "    \n",
    "    # Add new columns to DataFrame\n",
    "    for col_name, col_data in new_columns.items():\n",
    "        df_pandas[col_name] = col_data\n",
    "    \n",
    "    print(f\"Added {len(new_columns)} new scaling columns\")\n",
    "    \n",
    "    # Convert back to Polars if needed\n",
    "    enhanced_df = pl.from_pandas(df_pandas)\n",
    "    \n",
    "    return enhanced_df, scaling_info\n",
    "\n",
    "def extract_ptr_scaling_from_raw(stdf_file):\n",
    "    \"\"\"\n",
    "    Alternative method: Parse the file again and extract PTR records directly\n",
    "    This gives us access to the scaling fields that are already parsed\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import the internal stupidf modules to access raw records\n",
    "    try:\n",
    "        # This is a bit hacky but should work to get raw PTR records\n",
    "        from stupidf.records import Records\n",
    "        from stupidf.records.records import Record\n",
    "        \n",
    "        ptr_scaling = {}\n",
    "        \n",
    "        # Parse the file record by record\n",
    "        records = Records(stdf_file)\n",
    "        \n",
    "        for record in records:\n",
    "            if resolved := record.resolve():\n",
    "                if isinstance(resolved, Record) and hasattr(resolved, '__class__'):\n",
    "                    # Check if it's a PTR record\n",
    "                    if resolved.__class__.__name__ == 'PTR' or str(type(resolved)).endswith('PTR'):\n",
    "                        ptr = resolved\n",
    "                        test_num = ptr.test_num\n",
    "                        \n",
    "                        ptr_scaling[test_num] = {\n",
    "                            'res_scal': getattr(ptr, 'res_scal', 0),\n",
    "                            'llm_scal': getattr(ptr, 'llm_scal', 0), \n",
    "                            'hlm_scal': getattr(ptr, 'hlm_scal', 0),\n",
    "                            'units': getattr(ptr, 'units', ''),\n",
    "                            'low_limit': getattr(ptr, 'lo_limit', None),\n",
    "                            'high_limit': getattr(ptr, 'hi_limit', None)\n",
    "                        }\n",
    "        \n",
    "        print(f\"Extracted PTR scaling info for {len(ptr_scaling)} tests\")\n",
    "        return ptr_scaling\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"Could not import internal records module, using alternative method...\")\n",
    "        return extract_ptr_scaling_alternative(stdf_file)\n",
    "\n",
    "def extract_ptr_scaling_alternative(stdf_file):\n",
    "    \"\"\"\n",
    "    Alternative method using only the public API\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get rows which contain individual test results\n",
    "    rows = sf.get_rows(stdf_file)\n",
    "    \n",
    "    # This won't give us scaling info directly, but we can try to get it\n",
    "    # from the test information\n",
    "    stdf_parsed = sf.parse_stdf(stdf_file)\n",
    "    test_info = stdf_parsed['test_information'].to_pandas()\n",
    "    \n",
    "    ptr_scaling = {}\n",
    "    \n",
    "    # Extract what we can from test information\n",
    "    for _, row in test_info.iterrows():\n",
    "        if row['test_type'] == 'P':  # Parametric test\n",
    "            test_num = row['test_num']\n",
    "            ptr_scaling[test_num] = {\n",
    "                'res_scal': 0,  # Default, since not available in merged test info\n",
    "                'llm_scal': 0,\n",
    "                'hlm_scal': 0, \n",
    "                'units': row.get('units', ''),\n",
    "                'low_limit': row.get('low_limit', None),\n",
    "                'high_limit': row.get('high_limit', None)\n",
    "            }\n",
    "    \n",
    "    return ptr_scaling\n",
    "\n",
    "def analyze_scaling_results(enhanced_df, scaling_info):\n",
    "    \"\"\"\n",
    "    Analyze the results of the scaling operation\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"SCALING ANALYSIS RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    df_pandas = enhanced_df.to_pandas()\n",
    "    \n",
    "    # Find all scaling-related columns\n",
    "    scaled_cols = [col for col in df_pandas.columns if '_scaled' in col]\n",
    "    res_scal_cols = [col for col in df_pandas.columns if '_res_scal' in col]\n",
    "    units_cols = [col for col in df_pandas.columns if '_units' in col]\n",
    "    \n",
    "    print(f\"Created {len(scaled_cols)} scaled result columns\")\n",
    "    print(f\"Created {len(res_scal_cols)} scaling exponent columns\")\n",
    "    print(f\"Created {len(units_cols)} units columns\")\n",
    "    \n",
    "    # Show some examples\n",
    "    print(f\"\\nExample scaled columns: {scaled_cols[:5]}\")\n",
    "    print(f\"Example units columns: {units_cols[:5]}\")\n",
    "    \n",
    "    # Analyze scaling factors used\n",
    "    scaling_factors_used = set()\n",
    "    units_found = set()\n",
    "    \n",
    "    for test_num, info in scaling_info.items():\n",
    "        if info.get('res_scal') is not None:\n",
    "            scaling_factors_used.add(info['res_scal'])\n",
    "        if info.get('units'):\n",
    "            units_found.add(info['units'])\n",
    "    \n",
    "    print(f\"\\nScaling factors found: {sorted(scaling_factors_used)}\")\n",
    "    print(f\"Units found: {sorted(units_found)}\")\n",
    "    \n",
    "    # Show a detailed example for one test\n",
    "    if scaled_cols:\n",
    "        example_test = scaled_cols[0].replace('_scaled', '')\n",
    "        raw_col = example_test\n",
    "        scaled_col = f\"{example_test}_scaled\"\n",
    "        scal_col = f\"{example_test}_res_scal\"\n",
    "        \n",
    "        if all(col in df_pandas.columns for col in [raw_col, scaled_col, scal_col]):\n",
    "            print(f\"\\nDetailed example for test {example_test}:\")\n",
    "            \n",
    "            sample_data = df_pandas[[raw_col, scaled_col, scal_col]].dropna().head(5)\n",
    "            \n",
    "            for idx, row in sample_data.iterrows():\n",
    "                raw = row[raw_col]\n",
    "                scaled = row[scaled_col]\n",
    "                scal = row[scal_col]\n",
    "                \n",
    "                expected = raw * (10 ** scal) if scal != 0 else raw\n",
    "                print(f\"  Row {idx}: {raw:.6f} × 10^{scal} = {expected:.6f} (got {scaled:.6f})\")\n",
    "    \n",
    "    return enhanced_df\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to demonstrate the scaling workaround\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace with your STDF file path\n",
    "    stdf_file = \"your_file.stdf\"  # Change this!\n",
    "    \n",
    "    try:\n",
    "        # Extract scaling info and create enhanced DataFrame\n",
    "        enhanced_df, scaling_info = extract_scaling_info_and_apply(stdf_file)\n",
    "        \n",
    "        # Analyze the results\n",
    "        final_df = analyze_scaling_results(enhanced_df, scaling_info)\n",
    "        \n",
    "        print(f\"\\n✅ Successfully created enhanced DataFrame with scaling!\")\n",
    "        print(f\"   Original columns: {len(sf.parse_stdf(stdf_file)['df'].columns)}\")\n",
    "        print(f\"   Enhanced columns: {len(final_df.columns)}\")\n",
    "        \n",
    "        # Save the enhanced DataFrame if desired\n",
    "        # final_df.write_csv(\"enhanced_stdf_data.csv\")\n",
    "        \n",
    "        return final_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Quick test function you can run\n",
    "    def quick_test(stdf_file):\n",
    "        \"\"\"Quick test to see if scaling info is available\"\"\"\n",
    "        \n",
    "        print(f\"Testing scaling extraction for: {stdf_file}\")\n",
    "        \n",
    "        # Get raw data\n",
    "        raw = sf.get_raw_stdf(stdf_file)\n",
    "        \n",
    "        # Check test information\n",
    "        full_test_info = raw.test_data.full_test_information\n",
    "        \n",
    "        print(f\"Found {len(full_test_info)} test information records\")\n",
    "        \n",
    "        # Check a few records for scaling info\n",
    "        sample_tests = list(full_test_info.items())[:3]\n",
    "        \n",
    "        for (test_num, site, head), test_info in sample_tests:\n",
    "            print(f\"\\nTest {test_num} (site {site}, head {head}):\")\n",
    "            print(f\"  Units: {getattr(test_info, 'units', 'N/A')}\")\n",
    "            print(f\"  Low limit: {getattr(test_info, 'low_limit', 'N/A')}\")\n",
    "            print(f\"  High limit: {getattr(test_info, 'high_limit', 'N/A')}\")\n",
    "    \n",
    "    # Uncomment and modify to test:\n",
    "    # quick_test(\"your_file.stdf\")\n",
    "    # main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
